from mysklearn import myutils
import math
import numpy as np

class MyKNeighborsClassifier:
    """
        Purpose: represents a simple k nearest neighbors classifier.

        Attributes:
            n_neighbors (int): the number of k neighbors.
            X_train (list of list of numeric vals): - the list of training instances (samples).
                                                    - has shape: (n_train_samples, n_features)
            y_train (list of obj): - the target y values / labels corresponding to X_train
                                   - has shape: n_samples

        Notes: - Loosely based on sklearn's KNeighborsClassifier: https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html
               - Terminology: instance = sample = row and attribute = feature = column
               - Assumes data has been properly normalized before use.
    """
    def __init__(self, n_neighbors=3):
        """
            Purpose: the initializer for MyKNeighborsClassifier.

            Args:
                n_neighbors (int): the number of k neighbors.
        """
        self.n_neighbors = n_neighbors
        self.X_train = None
        self.y_train = None


    def fit(self, X_train, y_train):
        """
            Purpose: fits a kNN classifier to X_train and y_train.

            Args:
                X_train(list of list of numeric vals): The list of training instances (samples).
                    The shape of X_train is (n_train_samples, n_features)
                y_train(list of obj): The target y values (parallel to X_train)
                    The shape of y_train is n_train_samples

            Notes:
                Since kNN is a lazy learning algorithm, this method just stores X_train and y_train
        """
        self.X_train = X_train
        self.y_train = y_train


    def kneighbors(self, X_test):
        """
            Purpose: determines the k closes neighbors of each test instance.

            Args:
                X_test (list of list of numeric vals): - the list of testing samples.
                                                       - has shape: (n_test_samples, n_features).

            Returns:
                distances (list of list of float): a 2D list of k nearest neighbor distances for each instance in X_test.
                neighbor_indices (list of list of int): a 2D list of k nearest neighbor indices in X_train (parallel to distances).
        """
        distances = [] # to store each test instance's list of distances (that is is from each train instance).
        neighbor_indices = []

        # iterate over each instance in the test set.
        for row in X_test:
            dists = [] # to hold a row's sorted distances. 

            num_instances = len(row) # get the number of features in the test instance's row.

            # iterate over each instance in the train set and and compute its distance to the current test instance.
            for train_row in self.X_train:
                temp_dist = math.sqrt(sum((row[i] - train_row[i]) ** 2 for i in range(num_instances)))
                dists.append(temp_dist)

            # sort the distances (the k-nearest neighbors to the test instance).
            sorted_distances = np.argsort(dists) # the indices of the sorted distances. 

            indices = list(sorted_distances[:self.n_neighbors]) # only take the k closest neighbors. 
            sorted_dists = [dists[i] for i in indices]

            # append the current test instance's distance list and corresponding indices to the main distance list.
            distances.append(sorted_dists)
            neighbor_indices.append(indices)

        return distances, neighbor_indices
    

    def predict(self, X_test):
        """
            Purpose: generate predictions for test instances in X_test.

            Args:
                X_test (list of list of numeric vals): - the list of testing samples
                                                       - has shape: (n_test_samples, n_features)

            Returns:
                y_predicted (list of obj): The predicted target y values (corresponding to X_test)
        """
        y_predicted = []

        # find the lists of indices of each test instances k nearest neighbors.
        distances, neighbor_indices = self.kneighbors(X_test)

        # iterate through each test instances list of neighbor indexes. 
        for indices in neighbor_indices:
            # find labels of each neighbor.
            labels = [self.y_train[idx] for idx in indices]

            # intialize a dict to store counts for each label. 
            counts = {}
            
            for label in labels: 
                curr_label_count = counts.get(label, 0)
                counts[label] = curr_label_count + 1

            majority_label = max(counts, key=counts.get) # note: use get without args to consider/get the value of all keys.
           
            y_predicted.append(majority_label)

        return y_predicted 


class MyDummyClassifier:
    """
        Purpose: - represents a "dummy" classifier using the "most_frequent" strategy.
        
        Notes: - the "most_frequent" strategy: - a Zero-R classifier == it ignores X_train / produces "zero rules" from X_train.
                                               - looks ONLY at y_train to determine the most frequent class label.

        Attributes:
            most_common_label(obj): whatever the most frequent class label in the y_train passed into fit()

        Notes:
            Loosely based on sklearn's DummyClassifier: https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html
    """
    def __init__(self):
        """
            Purpose: the initializer for DummyClassifier.
        """
        self.most_common_label = None


    def fit(self, X_train, y_train):
        """
            Purpose: a dummy classifier to X_train and y_train.

            Args:
                X_train(list of list of numeric vals): - the list of training instances (samples).
                                                    - has shape: (n_train_samples, n_features)
                y_train(list of obj): - The target y values (parallel to X_train)
                                    - has shape: n_train_samples

            Notes: - Since Zero-R only predicts the most frequent class label, this method only saves the most frequent class label.
        """
        # find the most common class label.
        # create a dictionary to store the number of labels for each label in the dataset.
        class_label_counts = {}
        
        for label in y_train:
            curr_label_count = class_label_counts.get(label,0)
            class_label_counts[label] = curr_label_count + 1
            
        # find the label with the highest frequency
        self.most_common_label = max(class_label_counts, key=class_label_counts.get) 


    def predict(self, X_test):
        """
            Purpose: - generates predictions for test instances in X_test.

            Args:
                X_test (list of list of numeric vals): - the list of testing samples
                                                    - has shape:(n_test_samples, n_features)

            Returns:
                y_predicted (list of obj): - the predicted target y values (parallel to X_test)
        """
        if self.most_common_label is None:
            raise ValueError("Model has not been fitted yet. Call fit() before predict().")
        
        # generate a prediction for each test instance in X_test by referring to the most common class labe, as determined in fit().
        y_predicted = [self.most_common_label for _ in X_test]
        
        return y_predicted

